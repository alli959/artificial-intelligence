{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code examples (week 1)\n",
    "\n",
    "Topics:\n",
    "* Gradient descent (a.k.a. steepest descent)\n",
    "* Linear regression via the normal equations\n",
    "* Linear regression via stochastic gradient descent\n",
    "* Polynomial regression with the scikit-learn package\n",
    "* Regularized regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimize the function $f(\\theta_0,\\theta_1) = 4 \\theta_0^2 - 4 \\theta_0 \\theta_1 + 3 \\theta_1^2$ using steepest descent.\n",
    "\n",
    "The gradient of $f$ is $\\nabla f(\\theta) = (8 \\theta_0 - 4 \\theta_1, -4 \\theta_0 + 6 \\theta_1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6 0.8]\n",
      "[0.44 0.56]\n",
      "[0.312 0.4  ]\n",
      "[0.2224 0.2848]\n",
      "[0.1584 0.2029]\n",
      "[0.1128 0.1445]\n",
      "[0.0804 0.1029]\n",
      "[0.0572 0.0733]\n",
      "[0.0408 0.0522]\n",
      "[0.029  0.0372]\n",
      "[0.0207 0.0265]\n",
      "[0.0147 0.0189]\n",
      "[0.0105 0.0134]\n",
      "[0.0075 0.0096]\n",
      "[0.0053 0.0068]\n",
      "[0.0038 0.0049]\n",
      "[0.0027 0.0035]\n",
      "[0.0019 0.0025]\n",
      "[0.0014 0.0018]\n",
      "[0.001  0.0013]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(suppress=True, precision=4)\n",
    "\n",
    "alpha = 0.1 # Step length (may need to adjust)\n",
    "maxiter = 20\n",
    "\n",
    "dt = np.zeros(2) # Define a vector with 2 elements to hold the gradient\n",
    "t = np.array([1,1]) # Starting point\n",
    "\n",
    "for iter in range(0,maxiter):\n",
    "    # Gradient\n",
    "    dt[0] = 8*t[0] - 4*t[1]\n",
    "    dt[1] = -4*t[0] + 6*t[1]\n",
    "    \n",
    "    # Updating step\n",
    "    t = t - alpha*dt\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression \n",
    "\n",
    "This example shows how to read a small dataset from a text file (in csv format) and perform simple visualization using matplotlib.\n",
    "\n",
    "There are many ways to load data from files in Python, e.g. csvReader and Pandas. Here we use numpy.genfromtxt which is fairly basic but can often be used to get the job done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEGCAYAAABhMDI9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAN1klEQVR4nO3db4hl9X3H8fenu0nMSmw0Too66thU0hYJtgwhQfovkmDXZa0JwpbapASyLUW6CVjjsiCWkGJi/vigRNlaaVCbkFKkdpM0ayrb9kGFztbVbrqamMY/sQbHPohQHzSy3z64Z+T+pjO7c8c5984d3i8Y5p7fOWfO9zu/1c+cc+ecSVUhSdKSn5p0AZKkzcVgkCQ1DAZJUsNgkCQ1DAZJUmP7pAtYi3PPPbfm5uYmXYYkTZWjR4++VFUzo+43FcEwNzfHwsLCpMuQpKmS5Jn17OelJElSw2CQJDUMBklSw2CQJDUMBklSw2CQJDUMBklSw2CQJDUMBklSw2CQJDUMBklSw2CQJDUMBklSw2CQJDUMBklSw2CQJDUMBklSw2CQJDUMBklSw2CQJDUMBklSw2CQJDV6D4Yk25I8muRQt3xrkueTHOs+dvZdgyRp7baP4Rj7gBPAWUNjX6yqz43h2JKkEfV6xpBkFrgauLvP40iSNk7fl5LuAG4CTi4bvyHJ40nuSXL2Sjsm2ZtkIcnC4uJiz2VKkpb0FgxJdgEvVtXRZavuBN4BXA68AHx+pf2r6mBVzVfV/MzMTF9lSpKW6fM9hiuA3d2by2cAZyW5r6quX9ogyZ8Dh3qsQZI0ot7OGKpqf1XNVtUcsAd4uKquT3Le0GbXAsf7qkGSNLpx/FbScp9NcjlQwNPA70+gBknSKsYSDFV1BDjSvf7dcRxTkrQ+3vksSWoYDJKkhsEgSWoYDJKkhsEgSWoYDJKkhsEgSWoYDJKkhsEgSWoYDJKkhsEgSWoYDJKkhsEgSWoYDJKkhsEgSWoYDJKkhsEgSWoYDJKkhsEgSWoYDJKkhsEgSWoYDJKkhsEgSWoYDJKkhsEgSWoYDJKkhsEgSWoYDJKkhsEgSWoYDJKkhsEgSWoYDJKkhsEgSWoYDJKkhsEgSWoYDJKkhsEgSWr0HgxJtiV5NMmhZeM3Jqkk5/ZdgyRp7cZxxrAPODE8kORC4P3As2M4viRpBL0GQ5JZ4Grg7mWrvgjcBFSfx5ckja7vM4Y7GATAyaWBJLuB56vqsVPtmGRvkoUkC4uLiz2XKUla0lswJNkFvFhVR4fGdgAHgFtOt39VHayq+aqan5mZ6atMSdIy23v82lcAu5PsBM4AzgLuBS4BHksCMAv8W5J3V9WPeqxFkrRGvQVDVe0H9gMk+XXgxqr60PA2SZ4G5qvqpb7qkCSNxvsYJEmNPi8lvaaqjgBHVhifG8fxJUlr5xmDJKlhMEiSGgaDJKlhMEiSGgaDJKlhMEiSGgaDJKlhMEiSGgaDJKlhMEiSGgaDJKlhMEiSGgaDJKlhMEiSGgaDJKlhMEiSGgaDJKlhMEiSGgaDJKlhMEiSGgaDJKlhMEiSGgaDJKlhMEiSGgaDJKlhMEiSGgaDJKlhMEiSGqsGQ5JvJJkbXymSpM3gVGcMfwkcTnIgyRvGVI8kacK2r7aiqr6W5OvALcBCknuBk0PrvzCG+iRJY7ZqMHR+AvwP8CbgLQwFgyRpa1o1GJJcBXwBeBD45ap6ZWxVSZIm5lRnDAeA66rqO+MqRpI0ead6j+FXxlmIJGlz8D4GSVKj92BIsi3Jo0kOdcufSvJ4kmNJDic5v+8aJElrN44zhn3AiaHl26vqXVV1OXCIwa/DSpI2iV6DIckscDVw99JYVb08tMmZQPVZgyRpNKe7j+H1ugO4icE9EK9J8mngw8CPgd9Yaccke4G9ABdddFG/VUqSXtPbGUOSXcCLVXV0+bqqOlBVFwL3AzestH9VHayq+aqan5mZ6atMSdIyfV5KugLYneRp4KvA+5Lct2ybvwI+1GMNkqQR9RYMVbW/qmarag7YAzxcVdcnuXRos93AE33VIEkaXd/vMazktiTvZPDcpWeAP5hADZKkVYwlGKrqCHCke+2lI0naxLzzWZLUMBgkSQ2DQZLUMBgkSQ2DQZLUMBgkSQ2DQZLUMBgkSQ2DQZLUMBgkSQ2DQZLUMBgkSQ2DQZLUMBgkSQ2DQZLUMBgkSQ2DQZLUMBgkSQ2DQZLUMBgkSQ2DQZLUMBgkSQ2DQZLUMBgkSQ2DQZLUMBgkSQ2DQZLUMBgkSQ2DQZLUMBgkSQ2DQZLUMBgkSQ2DQZLUMBgkSQ2DQZLUMBgkSQ2DQZLU6D0YkmxL8miSQ93y7UmeSPJ4kgeSvLXvGiRJazeOM4Z9wImh5YeAy6rqXcB3gf1jqEGStEa9BkOSWeBq4O6lsao6XFWvdouPALN91iBJGk3fZwx3ADcBJ1dZ/1HgmyutSLI3yUKShcXFxb7qkyQt01swJNkFvFhVR1dZfwB4Fbh/pfVVdbCq5qtqfmZmpq8yJUnLbO/xa18B7E6yEzgDOCvJfVV1fZKPALuAK6uqeqxBkjSi3s4Yqmp/Vc1W1RywB3i4C4WrgE8Cu6vqlb6OL0lan0ncx/BnwFuAh5IcS3LXBGqQJK2iz0tJr6mqI8CR7vXPjeOYkqT18c5nSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVKj92BIsi3Jo0kOdcvXJflOkpNJ5vs+viRpNOM4Y9gHnBhaPg58EPinMRxbkjSiXoMhySxwNXD30lhVnaiqJ/s8riRp/fo+Y7gDuAk4OeqOSfYmWUiysLi4uPGVSZJW1FswJNkFvFhVR9ezf1UdrKr5qpqfmZnZ4OokSavp84zhCmB3kqeBrwLvS3Jfj8eTJG2A3oKhqvZX1WxVzQF7gIer6vq+jidJ2hhjv48hybVJfgi8F/h6km+NuwZJ0uq2j+MgVXUEONK9fgB4YBzHlSSNzjufJUkNg0GS1EhVTbqG00qyCDyzyupzgZfGWM44bMWeYGv2ZU/TYyv2dbqeLq6qkX/ffyqC4VSSLFTVlnrm0lbsCbZmX/Y0PbZiX3315KUkSVLDYJAkNbZCMBycdAE92Io9wdbsy56mx1bsq5eepv49BknSxtoKZwySpA1kMEiSGlMRDEk+leTxJMeSHE5y/irbXZXkySRPJbl5aPycJA8l+V73+ezxVb+yJLcneaLr64Ekb11lu31Jjnd/DvXjQ+O3Jnm++54cS7JzfNWvbAN62nTzBCP19Ymup+NJvpLkjG58mudqtZ6mdq6SvHNoLo4leXnp3+G0ztVpehp9rqpq038AZw29/iPgrhW22QZ8H/hZ4I3AY8Avdus+C9zcvb4Z+Mwm6OkDwPbu9WdWqgm4jMGfQt3B4LlW3wYu7dbdCtw46T42uKdNN08j9HUB8APgzd3y14Dfm/K5OlVPUztXy7bfBvyIwY1gUztXp+lp5LmaijOGqnp5aPFMYKV3zN8NPFVV/1lV/8vgb0Bc0627Bvhy9/rLwG/1VetaVdXhqnq1W3wEmF1hs18AHqmqV7pt/xG4dlw1jmoDetp08wRr7gsGQffmJNsZBN9/jaO+9diAnqZ9rpZcCXy/qlZ7ssLEbUBPI8/VVAQDQJJPJ3kO+B3glhU2uQB4bmj5h90YwM9U1QsA3ee391nrOnwU+OYK48eBX03ytiQ7gJ3AhUPrb+hOL+/ZLKfyQ9bT02afJ1ilr6p6Hvgc8CzwAvDjqjo8tMnUzdVpeprauVpmD/CVZWNTN1fLLO9p5LnaNMGQ5NvddczlH9cAVNWBqroQuB+4YaUvscLYRH8X93Q9ddscAF5l0Fejqk4wOHV8CPh7BpfHln5yuBN4B3A5g/9oP99vN6/V22dPE/N6++r+B3INcAlwPnBmkqU/TDWVc3Wanibm9fY1tM0bgd3AXw8NT+VcDW2zUk+jm/T1s3Vcb7sYOL7C+HuBbw0t7wf2d6+fBM7rXp8HPDnpPrpaPgL8C7Bjjdv/KfCHK4zPrfQ9mbaeNus8raUv4DrgL4aWPwx8aZrn6lQ9TfNcDW13DXD4FOunZq5O1dN65mrTnDGcSpJLhxZ3A0+ssNm/ApcmuaRLzT3Ag926Bxl8Y+k+/21fta5VkquATwK7q+qVU2z39u7zRcAH6U4Rk5w3tNm1DC7RTNTr7YlNOE+w5r6eBd6TZEeSMLjOe6Lbf1rnatWemO65WvLbLLuMNMVzteT/9cR65mrSSbjGtPwbBhP0OPB3wAXd+PnAN4a22wl8l8FvJx0YGn8b8A/A97rP52yCnp5i8J7Ise7jrlV6+mfgPxhccrlyaPxe4N+778mDdD8RTHlPm26eRuzrTxj80HK8m583bYG5Wq2naZ+rHcB/Az+9bP9pnqvVehp5rnwkhiSpMRWXkiRJ42MwSJIaBoMkqWEwSJIaBoMkqWEwSCNKcmGSHyQ5p1s+u1u+eNK1SRvBYJBGVFXPMXh0wm3d0G3AwdrED2KTRuF9DNI6JHkDcBS4B/gY8Es1eKqvNPW2T7oAaRpV1U+S/DGDBwF+wFDQVuKlJGn9fpPBEzgvm3Qh0kYyGKR1SHI58H7gPcAnlj18TZpqBoM0ou5Jo3cCH6+qZ4HbGfxBG2lLMBik0X0MeLaqHuqWvwT8fJJfm2BN0obxt5IkSQ3PGCRJDYNBktQwGCRJDYNBktQwGCRJDYNBktQwGCRJjf8DK6Srw88S/MkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data=np.genfromtxt('data/linear_reg.csv', delimiter=',', skip_header=1) # Columns: x, y\n",
    "print(data.shape) # Sanity check\n",
    "n=data.shape[0]\n",
    "\n",
    "# Construct data matrix for linear regression\n",
    "# Model: y= θ_0 + θ_1*x_1 + ... + θ_p*x_p\n",
    "y=data[:,-1] # Output variable is in the last column in this file\n",
    "\n",
    "# Insert a column of ones (intercept term)\n",
    "X=np.c_[np.ones(n), data[:,0:-1]] # Include all columns from 'data' except the last\n",
    "\n",
    "\n",
    "# Plot the data\n",
    "plt.scatter(X[:,1],y)\n",
    "plt.plot(-2.84971111, 43.20411495)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact solution: theta= [-2.84971111 43.20411495]\n"
     ]
    }
   ],
   "source": [
    "# Obtain the regression coefficients by solving the \"normal equations\", X'Xθ = X'y, directly\n",
    "# This is the traditional way of solving least squares problems (\"exact\" solution)\n",
    "theta_ex = np.linalg.solve(X.T.dot(X), X.T.dot(y))\n",
    "print('Exact solution: theta=', theta_ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic gradient descent (SGD)\n",
    "This example shows how the SGD algorithm can be used to find solutions to linear least squares problems.\n",
    "\n",
    "NB This is a very primitive implementation of SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD approximation: [-2.0873307  38.79133652]\n"
     ]
    }
   ],
   "source": [
    "# SGD\n",
    "\n",
    "alpha=0.1  # May have to be decreased\n",
    "maxiter=10  # May have to be increased\n",
    "\n",
    "p=X.shape[1]\n",
    "theta=np.zeros(p)\n",
    "for iter in range(0,maxiter):\n",
    "    i = np.random.randint(n) # Select one training example uniformly at random\n",
    "    error = np.dot(theta,X[i,:]) - y[i]\n",
    "    for j in range(0,p):\n",
    "        theta[j] = theta[j] - alpha*error*X[i,j]\n",
    "print('SGD approximation:', theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
